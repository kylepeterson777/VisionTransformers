{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9580f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a ViT model for prediction on custom dataset #\n",
    "# Kyle T. Peterson, Ph.D.\n",
    "# 09/02/2022\n",
    "\n",
    "pip install hugsvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc789e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch connected to 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "# verify GPU is availalbe and compatible with Pytorch\n",
    "import torch\n",
    "GPU = torch.cuda.is_available()\n",
    "if GPU >= 1:\n",
    "    print(\"Pytorch connected to \" + str(torch.cuda.device_count()) + \" GPUs\")\n",
    "else:\n",
    "    print(\"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1827ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from hugsvision.inference.VisionClassifierInference import VisionClassifierInference\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from hugsvision.dataio.VisionDataset import VisionDataset\n",
    "from hugsvision.nnet.VisionClassifierTrainer import VisionClassifierTrainer\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b873182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Datasets...\n",
      "Balance train dataset...\n",
      "The less represented label in train as 3193 occurrences\n",
      "Size of train after balancing is 9579\n",
      "train_ds:  7663\n",
      "+---------+------------+-----------+------------+-------+\n",
      "| Dataset | HighDamage | LowDamage | NonDamaged | Total |\n",
      "+---------+------------+-----------+------------+-------+\n",
      "|  Train  |    2580    |   2537    |    2546    | 7663  |\n",
      "|  Test   |    613     |    656    |    647     | 1916  |\n",
      "+---------+------------+-----------+------------+-------+\n"
     ]
    }
   ],
   "source": [
    "# import and partition dataset\n",
    "train, test, id2label, label2id = VisionDataset.fromImageFolder(\n",
    "  \"F:/Bayer/Peterson/Cotton-VMD/Data/Labeled/High_Low_NonDamage/\",\n",
    "  test_ratio   = 0.2,\n",
    "  balanced     = True,\n",
    "  augmentation = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac204631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for transfer learning\n",
    "\n",
    "#VIT_base_patch16_224 = 'google/vit-large-patch16-224-in21k' \n",
    "VIT_small_patch16_224 = 'facebook/deit-small-patch16-224'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ae07680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/deit-small-patch16-224/resolve/main/config.json from cache at C:\\Users\\Bizon/.cache\\huggingface\\transformers\\05cabc43021b4900bf7f44d2d29e29a1dc3d73dba99f94b6f4fca9b3e936bf6f.b21bf2d3ca43e4a73eba56781079fde385128616017d5d242728ae8bdfee3277\n",
      "Model config ViTConfig {\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"HighDamage\",\n",
      "    \"1\": \"LowDamage\",\n",
      "    \"2\": \"NonDamaged\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"HighDamage\": \"0\",\n",
      "    \"LowDamage\": \"1\",\n",
      "    \"NonDamaged\": \"2\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.19.2\"\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/deit-small-patch16-224/resolve/main/pytorch_model.bin from cache at C:\\Users\\Bizon/.cache\\huggingface\\transformers\\02efb2148eb9e9ce4dfac5969e1abeab75211e44ee879047e30118cd5f8bb827.2fc3f4ff13b6faf4c5ee1f6176596ae27b2318b50df2128602eb85dff27e8cc3\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at facebook/deit-small-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 384]) in the checkpoint and torch.Size([3, 384]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading feature extractor configuration file https://huggingface.co/facebook/deit-small-patch16-224/resolve/main/preprocessor_config.json from cache at C:\\Users\\Bizon/.cache\\huggingface\\transformers\\aa14a5be5c60ca36f6bee47fdffe1aba4486bb6da8cf2fdc0f7cd45b937a1a34.c322cbf30b69973d5aae6c0866f5cba198b5fe51a2fe259d2a506827ec6274bc\n",
      "Feature extractor ViTFeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"size\": 224\n",
      "}\n",
      "\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'HighDamage', '1': 'LowDamage', '2': 'NonDamaged'}\n",
      "{'HighDamage': '0', 'LowDamage': '1', 'NonDamaged': '2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7663\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer builded!\n",
      "Start Training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24000' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24000/24000 1:36:05, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.242682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.257516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.323720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.316014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.351021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.383905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.421006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.407052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.470709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.503962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.542879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.558429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.689460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.728827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.708031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.749407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.621924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.761791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.835391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.776998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.730064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.850250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.867073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.938098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.936752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.979970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.928632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.622604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.852987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.709801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.738784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.750815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.830806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.801636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.853109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.871762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.896424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.908803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.892435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>0.931435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>0.933684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.967235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.780846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.752548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.806161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.776188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.712241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.827282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.899243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.896416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.977198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.926451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.970625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.964834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.975213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.978944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.943653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.944861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>1.007024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>1.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>1.019112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>1.033357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>1.007660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>1.019686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>1.034556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>1.037254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.022212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.035073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>1.033959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>1.024686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.934361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.982936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>1.039005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>1.026457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>1.045435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.979864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>1.037305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>1.043943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>1.053288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>1.049261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>1.060492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>1.063350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>1.056822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>1.073514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>1.063503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>1.066024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>1.070716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>1.071094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>1.073410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>1.073038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>1.075227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.077019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.077619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>1.079508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>1.080382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>1.081678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>1.081876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.083548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03\\checkpoint-10000\n",
      "Configuration saved in F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03\\checkpoint-10000\\config.json\n",
      "Model weights saved in F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03\\checkpoint-10000\\pytorch_model.bin\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03\\checkpoint-20000\n",
      "Configuration saved in F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03\\checkpoint-20000\\config.json\n",
      "Model weights saved in F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03\\checkpoint-20000\\pytorch_model.bin\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03/trainer/\n",
      "Configuration saved in F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03/trainer/config.json\n",
      "Model weights saved in F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03/trainer/pytorch_model.bin\n",
      "Configuration saved in F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03/model/config.json\n",
      "Model weights saved in F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03/model/pytorch_model.bin\n",
      "Feature extractor saved in F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03/feature_extractor/preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: \u001b[93mF:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "trainer = VisionClassifierTrainer(model_name= \"Cotton-VIT-High_Low_No\",\n",
    "                                  train = train,test = test,\n",
    "                                  output_dir= \"F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/\",\n",
    "                                  max_epochs= 100,batch_size= 32, lr = 2e-5,\n",
    "                                  model = ViTForImageClassification.from_pretrained(VIT_small_patch16_224,ignore_mismatched_sizes=True,\n",
    "                                                                                    num_labels = len(label2id),label2id=label2id,id2label=id2label),\n",
    "                                  feature_extractor = ViTFeatureExtractor.from_pretrained(VIT_small_patch16_224,ignore_mismatched_sizes=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7a599d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1916/1916 [00:34<00:00, 55.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  HighDamage     0.8342    0.8287    0.8314       613\n",
      "   LowDamage     0.8407    0.8369    0.8388       656\n",
      "  NonDamaged     0.9878    0.9985    0.9931       647\n",
      "\n",
      "    accuracy                         0.8888      1916\n",
      "   macro avg     0.8876    0.8880    0.8878      1916\n",
      "weighted avg     0.8883    0.8888    0.8885      1916\n",
      "\n",
      "Logs saved at: \u001b[93mF:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer/COTTON-VIT-HIGH_LOW_NO/100_2022-09-01-18-06-03\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "ref, hyp = trainer.evaluate_f1_score() \n",
    "\n",
    "cm = confusion_matrix(ref, hyp)\n",
    "labels = list(label2id.keys())\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 8}, fmt=\"\")\n",
    "plt.savefig(\"F:/Bayer/Peterson/Cotton-VMD/Modeling/Classification/Transformer//conf_matrix-ViT.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67b04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
